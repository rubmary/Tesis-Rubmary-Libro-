\section{Equilibrio correlacionado}

Aunque el equilibrio de Nash es uno de los principales conceptos de solución, es importante destacar que éste no garantiza el mejor resultado si los jugadores toman sus decisiones en conjunto. Si los jugadores pueden correlacionar sus acciones, pueden existir estrategias con mayores ganancias para ellos. 
Esto puede ser obtenido mediante un equilibrio correlacionado (Definición \ref{def:equilibrio-correlacionado}, \cite{bib:correlated-equilibrium}), una generalización del equilibrio de Nash. Todo equilibrio de Nash es un equilibrio correlacionado, pero este último permite otras soluciones importantes \cite{bib:correlated-equilibrium}. La relación entre los conceptos de equilibro de Nash y correlacionado se muestra en los Teoremas \ref{theo:nash-correlacionado} y \ref{theo:correlacionado-nash}.

\begin{definition}
\label{def:equilibrio-correlacionado}
Una distribución $\psi\in\Delta(S)$ es un \textbf{equilibrio correlacionado} si y sólo si para cualquier jugador $i$, y para cualesquiera estrategias puras $x, y \in S_i$,
\begin{alignat}{1}
\label{eq:equilibrio-correlacionado}
\sum_{s_{-i}\in S_{-i}} \psi(x,s_{-i}) [ u_i(x,s_{-i}) - u_i(y,s_{-i})]\ \geq\ 0 \,.
\end{alignat}
\end{definition}

Si en la desigualdad \eqref{eq:equilibrio-correlacionado} se cambia el $0$ por un $\epsilon > 0$ se obtiene la definición de $\epsilon$-equilibrio correlacionado.


\begin{theorem}
\label{theo:nash-correlacionado}
Si $\sigma$ es un equilibrio de Nash, entonces $\sigma$ es un equilibrio correlacionado.
\end{theorem}
\begin{proof}
Sea $\sigma$ un equilibrio de Nash, sean $x,y\in S_i$ estrategias puras distintas cualesquiera para el jugador $i$, y sea $\sigma'_i$ una estrategia mixta cualquiera para el jugador $i$. Por el Lema~\ref{lemma:2},
\begin{alignat}{1}
  \sigma_i(x) \sum_{s_{-i}} u_i(x,s_{-i}) \sigma_{-i}(s_{-i})\ \geq\  \sigma_i(x)\sum_{s_{-i}} u_i(y,s_{-i}) \sigma_{-i}(s_{-i}) \,.
\end{alignat}
Es decir,
\begin{alignat}{1}
  0\ \leq\ \sigma_i(x) \sum_{s_{-i}} \sigma_{-i}(s_{-i}) [u_i(x,s_{-i}) - u_i(y,s_{-i})]\ =\ \sum_{s_{-i}} \sigma(x,s_{-i}) [u_i(x,s_{-i}) - u_i(y,s_{-i})] \,.
\end{alignat}
%\begin{alignat}{2}
%  &\Rightarrow\quad
%  &&\sigma_i(x)\sum_{\substack{s \in S \\ s_i = y}} u_i(s) \sigma_{-i}(s_{-i})  \leq\ \sigma_i(x) \sum_{\substack{s \in S \\ s_i = x}} u_i(s) \sigma_{-i}(s_{-i}) \\
%	& \Rightarrow\quad & 0\ &\leq\ \sigma_i(x) \sum_{\substack{s \in S \\ s_i = x}} u_i(s) \sigma_{-i}(s_{-i}) -  \sigma_i(x)\sum_{\substack{s \in S \\ s_i = y}} u_i(s) \sigma_{-i}(s_{-i}) \\
%	& \Rightarrow\quad & 0\ &\leq\  \sum_{\substack{s \in S \\ s_i = x}} u_i(s) \sigma(s) -  \sum_{\substack{s \in S \\ s_i = y}} u_i(s) \sigma(s) \\
%	& \Rightarrow\quad & 0\ &\leq\  \sum_{\substack{s \in S \\ s_i = x}} \sigma(s) [u_i(s)  -  u_i(y, s)]
%\end{alignat}
Luego, $\sigma$ es un equilibrio correlacionado.
\end{proof}

\begin{theorem}
\label{theo:correlacionado-nash}
Sea $\psi\in\Delta(S)$ un equilibrio correlacionado. Si $\psi$ se factoriza como $\psi=\prod_{i\in N} \sigma_i$ donde $\{\sigma_i\}_{i\in N}$ es un conjunto de estrategias mixtas para cada jugador (i.e., $\psi(s)=\prod_{i \in N} \sigma_i(s_i)$ para todo $s\in S$), entonces $\psi$ es un equilibrio de Nash.
\end{theorem}

\begin{proof}
Sea $\psi= \prod_{i \in N} \sigma_i$ un equilibrio correlacionado en forma factorizada. Debemos mostrar que para cualquier jugador $i$ y estrategia mixta $\sigma'_i$ para el jugador $i$, se cumple $u_i(\sigma) \geq u_i(\sigma'_i, \sigma_{-i})$.

Sean $x$ y $y$ estrategias puras para el jugador $i$.
Como $\sigma$ es un equilibrio correlacionado,
\begin{alignat}{1}
\label{eq:1:theo:correlacionado-nash}
0\ \leq\ %\sum_{\substack{s \in S \\ s_i = x}} \sigma(s)[u_i(s) - u_i(y, s_{-i})] = 
\sigma_i(x) \sum_{s_{-i}} \sigma_{-i}(s_{-i})[u_i(x, s_{-i}) - u_i(y, s_{-i})] \,.
\end{alignat}
Al sumar sobre $x\in S_i$ obtenemos, 
\begin{alignat}{2}
\label{eq:2:theo:correlacionado-nash}
0\ \leq\ \sum_{x\in S_i} \sum_{s_{-i}} \sigma(x,s_{-i}) [u_i(x, s_{-i}) - u_i(y, s_{-i})]\ =\ \sum_s \sigma(s) [u_i(s) - u_i(y, s_{-i})] \,.
\end{alignat}
Si $x^* \in S_i$ es tal que $\sigma_i(x^*)>0$, obtenemos de \eqref{eq:1:theo:correlacionado-nash} al multiplicar por $\sigma'_i(y)$ y sumar sobre $y\in S_i$:
\begin{alignat}{1}
\label{eq:3:theo:correlacionado-nash}
\sum_{y \in S_i} \sigma'_i(y) \sum_{s_{-i}} \sigma_{-i} (s_{-i}) [u_i(x^*, s_{-i}) - u_i(y, s_{-i})]\ =\ \sum_{s} \sigma'(s) [u_i(x^*, s_{-i}) - u_i(s)]\ \geq\ 0
\end{alignat}
donde $\sigma'$ denota la estrategia $\sigma'=(\sigma'_i,\sigma_{-i})$. 
Al sumar \eqref{eq:2:theo:correlacionado-nash} y
\eqref{eq:3:theo:correlacionado-nash}, obtenemos que para cualquier $y$ y $x^*$ tal que $\sigma_i(x^*)>0$:
\begin{alignat}{1}
\label{eq:4:theo:correlacionado-nash}
\sum_{s \in S} u_i(s) [\sigma(s) - \sigma'(s)] - \sum_{s \in S} \sigma(s)u_i(y, s_{-i}) + \sum_{s \in S} \sigma'(s) u_i(x^*, s_{-i})\ \geq\ 0\ \,.
\end{alignat}
Por otra parte, note que:
\begin{alignat}{1}
  \sum_{s \in S} \sigma(s) u_i(x^*,s_{-i}) - \sum_{s \in S} &\sigma'(s) u_i(x^*,s_{-i}) \\
    &\qquad=\ \sum_{s_{-i}} u_i(x^*,s_{-i}) \sigma_{-i}(s_{-i}) \sum_{z\in S_i} [\sigma_i(z) - \sigma'_i(z)] \\
    &\qquad=\ \sum_{s_{-i}} u_i(x^*,s_{-i}) \sigma_{-i}(s_{-i}) \biggl[ \sum_{z\in S_i} \sigma_i(z) - \sum_{z\in S_i} \sigma'_i(z) \biggr] \\
    &\qquad=\ 0 \,.
\end{alignat}
Luego, al tomar $y=x^*$ en \eqref{eq:4:theo:correlacionado-nash},
\begin{alignat}{1}
 \sum_{s \in S} u_i(s) [\sigma(s) - \sigma'(s)]\ =\ \sum_{s \in S} u_i(s)\sigma(s) - \sum_{s \in S} u_i(s)\sigma'(s)\ =\ u_i(\sigma) - u_i(\sigma'_i, \sigma_{-i})\ \geq\ 0 \,.
\end{alignat}
Como $\sigma'_i$ es una estrategia cualquiera para el jugador $i$, $\sigma$ es un equilibrio de Nash.
\end{proof}

A diferencia del conjunto de equilibrios de Nash, el cual es un conjunto matemáticamente complejo (un conjunto de puntos fijos), el conjunto de equilibrios correlacionados en un conjunto bastante simple. En particular, el conjunto de equilibrios correlacionado es un politopo (generalización de un polígono en $\mathbb{R}^N$) convexo. Por lo tanto puede esperarse que existan procedimientos simples para calcular equilibrios correlacionados \cite{bib:correlated-equilibrium}.

\begin{theorem}
Sean $\sigma$ y $\sigma'$ dos equilibrios correlacionados, y $\alpha$ un número real en $(0,1)$. Entonces, la distribucion $\alpha\sigma + (1-\alpha)\sigma'$ es un equilibrio correlacionado.
\end{theorem}
\begin{proof}
\Blai{hacer demostracion}
\end{proof}

\subsection{Blackwell's Approachability Theorem}
Antes de presentar los procedimientos que llevan a equilibrios correlacionados, es importante enunciar el Teorema de Aproximación de Blackwell, \textit{Blackwell's Approachability Theorem}, base para la obtención de los procedimientos que calculan equilibrios correlacionados. El enunciado del teorema, las definiciones utilizadas y los procedimientos mostrados son presentados en \cite{bib:correlated-equilibrium}.

El marco teórico en el cual se aplica el teorema está conformado por: (1)~un \textbf{decididor} $i$ que toma decisiones de un conjunto finito de acciones $S_i$, (2)~un \textbf{oponente} $-i$ que toma decisiones de un conjunto finito de acciones $S_{-i}$, (3)~un \textbf{conjunto indexado} denotado por $L$, y (4)~un \textbf{vector de pagos} $v(s_i, s_{-i}) \in \mathbb{R}^{|L|}$.
El decididor y oponente toman decisiones $s_t=(s^t_i,s^t_{-i})\in S_i\times S_{-i}$ indexadas en tiempo $t\geq 1$. El problema planteado consiste en ver si el decididor puede garantizar que el promedio de pagos $D_t$ a tiempo $t$, definido por $D_t=\frac{1}{t}\sum_{\tau=1}^t v(s_\tau)=\frac{1}{t}\sum_{\tau=1}^t v(s^\tau_i,s^\tau_{-i})$, \emph{alcanza} el conjunto $\mathbb{R}^{|L|}$.
Antes de enunciar el teorema es necesario presentar las definiciones de distancia de un punto a un conjunto (Definición \ref{def:distancia}), un conjunto alcanzable (Definición \ref{def:alcanzable}) y de función de soporte (Definición \ref{def:funcion-soporte}).

\begin{definition}
\label{def:distancia}
Sea $A$ un conjunto cerrado y convexo en $\mathbb{R}^n$, y $x \in \mathbb{R}^n$ un punto cualquiera. La \textbf{distancia} de $x$ a $A$ es definida por
\begin{alignat}{1}
\text{dist}(x, A)\ =\ \min\{ \|x - a\| : a \in A \}
\end{alignat}
donde $\|\cdot\|$ denota la distancia euclidiana en $\mathbb{R}^n$.
\end{definition}

\begin{definition}
\label{def:alcanzable}
Sea $\mathcal{C}$ un conjunto convexo y cerrado en $\mathbb{R}^{|L|}$. El conjunto $\mathcal{C}$ es \textbf{alcanzable} por el decididor $i$ si hay un procedimiento para $i$ que garantiza que $D_t$ alcanza a $\mathcal{C}$; es decir. $dist(D_t, \mathcal{C}) \rightarrow 0$ (a.s.) sin importar la elección del oponente $-i$.
\end{definition}

\begin{definition}
\label{def:funcion-soporte}
Sea $\mathcal{C} \in \mathbb{R}^n$ un conjunto. La \textbf{función de soporte} $w_{\mathcal{C}}$ para el conjunto $\mathcal{C}$, es definida por
\begin{alignat}{1}
	w_{\mathcal{C}}(\lambda)\ =\ \sup\{\lambda \cdot c : c \in \mathcal{C} \}
\end{alignat}
donde $\cdot$ denota el producto interno en $\mathbb{R}^n$.
\end{definition}

Dado un conjunto convexo y cerrado $\mathcal{C}$ denotaremos con $F(x)$ el punto (único) más cercano a $x$ de $C$, y con $\lambda(x)= x - F(x)$ el \emph{vector normal exterior} a $\mathcal{C}$ en el punto $x$ \Blai{*** def? ***}.
El Teorema de Blackwell (Te)orema~\ref{theo:blackwell} establece una condición necesaria y suficiente para el problema planteado previamente.

\begin{theorem}
\label{theo:blackwell}
Sea $\mathcal{C} \subseteq \mathbb{R}^{|L|}$ un conjunto convexo y cerrado con función de soporte $w_{\mathcal{C}}$. Entonces, $\mathcal{C}$ es alcanzable por $i$ si y sólo si para todo $\lambda \in \mathbb{R}^{|L|}$, existe una estrategia mixta $q_{\lambda} \in \Delta(S_i)$ para el decididor $i$ tal que para todo $s_{-i}\in S_{-i}$:
\begin{alignat}{1}
  \lambda \cdot v(q_{\lambda}, s_{-i})\ \leq\ w_{\mathcal{C}}(\lambda) \,.
\end{alignat}
En esta expresión, $v(q, s_{-i})$ denota $\sum_{s_i \in S_i} q(s_i)u_i(s_i, s_{-i})$. 
Además, el siguiente procedimiento garantiza que $dist(D_t, \mathcal{C}) \rightarrow 0$ (a.s.) cuando $t \rightarrow \infty$: en el tiempo $t+1$, jugar $q_{\lambda(D_t)}$ si $D_t \notin \mathcal{C}$, y jugar arbitrariamente si $D_t \in \mathcal{C}$.
\end{theorem}

\Blai{**** Algún ejemplo? ****}

\subsection{Regret Matching}
Una vez enunciado el Teorema de Aproximación de Blackwell, es posible plantear la siguiente pregunta ?`Hay procedimientos adaptativos simples que siempre lleven a un equilibrio correlacionado? A continuación se describen tres procedimientos, dos de los cuales llevan a equilibrios correlacionados \cite{bib:correlated-equilibrium}.

\subsubsection{Procedimiento A: Regret condicional}

Sea $\Gamma$ un juego en forma normal el cual es jugado repetidamente a través del tiempo $t = 1, 2, \ldots $. 
Sea $h_t = (s^\tau)_{\tau = 1}^t \in \prod_{\tau = 1}^{t} S$ la historia del juego al inicio del tiempo $t+1$. El jugador $i \in N$ elige su estrategia con una distribución de probabilidad $p_{t+1}^i \in \Delta(S_i)$, definida de la siguiente manera.

Para cada par de estrategias $j, k \in S_i$, supongamos que el jugador $i$ remplaza la estrategia $j$ (cada vez que la jugó en el pasado) por la estrategia $k$. Luego, su ganancia a tiempo $1\leq \tau \leq t$ hubiera sido:
\begin{alignat}{1}
W_i^{\tau}(j,k)\ =\ 
\begin{cases}
u_i(k, s_{-i}^{\tau}) &\text{ si } s_i = j \,, \\
u_i(s^\tau) & \text{en otro caso.} 
\end{cases}
\end{alignat}
La diferencia resultante en el promedio de la función de pago, denotada con $D_i^t(j, k)$, para el jugador $i$ sería:
\begin{alignat}{1}
  D_i^t(j, k)\ 
    =\ \frac{1}{t} \sum_{\tau = 1}^{t} W_i^{\tau}(j, k) - \frac{1}{t} \sum_{\tau = 1}^{t} u_i(s^{\tau})\ 
	=\ \frac{1}{t} \sum_{\substack{1\leq \tau \leq t \\s^\tau_i = j}} u_i(k, s_{-i}^{\tau}) - u_i(s^{\tau}) \,.
\end{alignat}
Finalmente, definimos
\begin{alignat}{1}
\label{eq:regret}
R_i^t(j, k)\ =\ [D_i^t(j, k)]^+\ =\ \max(0, D_i^t(j, k)) \,.
\end{alignat}

La expresión \eqref{eq:regret} se puede interpretar como una medida de ``arrepentimiento'' del jugador $i$ de haber elegido la acción $j$ en vez de la acción $k$ en el pasado, y por lo tanto, dicha medida es denominada \textit{regret}.

Fijemos un número $\mu > 0$ suficientemente grande. Sea $j \in S_i$ la última estrategia jugada por el jugador $i$, es decir $j = s_i^t$. Luego, la distribución de probabilidad $p_{t+1}^i \in \Delta(S_i)$ usada por el jugador $i$ a tiempo $t+1$ es definida como:
\begin{alignat}{1}
\label{eq:proc-A}
  \begin{cases}
    p_{t+1}^i(k)\ :=\  \frac{1}{\mu} R_t^i(j, k) & \text{ si } k \neq j \,, \\
    p_{t+1}^i(j)\ :=\ 1 - \sum_{k \in S_i, k \neq j} p_{t+1}^i(k) \,.
  \end{cases}
\end{alignat}
La distribución inicial $p_{1}^i \in \Delta(S_i)$, a tiempo $t=1$, es elegida de forma arbitraria.

Para cada tiempo $t$, sea $z_t \in \Delta(S)$ la distribución empírica de las $N$-tuplas jugadas hasta tiempo $t$, es decir:
$z_t(s) := \frac{1}{t} |\{1\leq\tau \leq t : s^{\tau} = s \}|$. El siguiente teorema enuncia que el procedimiento arriba descrito produce un equilibrio correlacionado.

\begin{theorem}[\cite{bib:correlated-equilibrium}]
\label{theo:conv-proc-A}
Si cada jugador juega de acuerdo al procedimiento descrito por \eqref{eq:proc-A}, entonces la distribución empírica del juego $z_t$ converge (a.s.) cuando $t \rightarrow \infty$ al conjunto de equilibrios correlacionado del juego $\Gamma$.
\end{theorem}

Es importante destacar que $z_t$ no tiene que converger necesariamente a un punto equilibrio correlacionado. El Teorema~\ref{theo:conv-proc-A} es equivalente al siguiente enunciado: para todo $\varepsilon > 0$, existe un tiempo $T_0 = T_0(\varepsilon)$ tal que para todo $t \geq T_0$ podemos encontrar un equilibrio correlacionado $\psi_t$ que está distancia menor que $\varepsilon$ de $z_t$.

En el procedimiento descrito cada jugador tiene dos opciones en cada período: continuar jugando con la última estrategia, o cambiarla por otra estrategia cuyas probabilidades son proporcionales a cuanto mayor hubiese sido su ganancia acumulada si hubiese hecho ese cambio en el pasado. El procedimiento planteado es simple, tanto de entender y explicar, como de implementar. Además en cada período no sólo se elige la mejor respuesta, todas las respuestas mejores a la actual pueden ser escogidas con probabilidades que son proporcionales a sus ganancias aparentes (medidas por el \textit{regret}). Este tipo de procedimientos son llamados procedimientos de \textit{regret matching}. Por último, el procedimiento tiene inercia: la estrategia jugada previamente importa, siempre hay una probabilidad positiva de continuar jugando la misma estrategia, y más aún, sólo se cambiará de estrategia si hay una razón para hacerlo.

La siguiente proposición conecta el conjunto de equilibrios correlacionados con la noción de regret: \Blai{*** La relevancia de la siguiente proposición, así como su prueba, no están claras. Revisar esto. Me imagino que lo que se quiere establecer es que el regret tiendo a cero cuando se utiliza el procedimiento, pero esto no esta claro ***}

\begin{proposition}
\label{prop:no-regret}
Sea $(s_t)_{t = 1, 2, ...}$ una secuencia de juegos de $\Gamma$, y sea $\varepsilon \geq 0$ un número no negativo.
Entonces, $\limsup_{t \rightarrow \infty} R_i^t(j, k) \leq \varepsilon$ para cada $i$ y cada $j, k \in S_i$, con $j \neq k$, si y sólo si la secuencia de distribuciones empíricas $z_t$ converge al conjunto de $\varepsilon$-equilibrio correlacionado.
\end{proposition}

\begin{proof}
Note que:
\begin{alignat}{1}
  D_i^t(j, k)\ 
    &=\ \frac{1}{t} \sum_{\substack{1\leq \tau \leq t \\ s_i^{\tau}=j}} u_i(k, s_{-i}^{\tau}) - u_i(s^{\tau}) \\
    &=\ \sum_{ \substack{s \in S \\ s_i = j}} \frac{1}{t} |\{1\leq\tau \leq t : s^{\tau} = s\}|\,[u_i(k, s_{-i}) - u_i(s)] \\
    &=\ \sum_{ \substack{s \in S \\ s_i = j}} z_t(s)\,[u_i(k, s_{-i}) - u_i(s)] \,.
\end{alignat}
Entonces, para cualquier subsecuencia $z_{t'}$ de $z_t$ tal que $z_{t'} \rightarrow \psi \in \Delta(s)$ (es decir, converge) se tiene que:
\begin{alignat}{1}
	D'_{t'}(j, k)\ \longrightarrow\ \sum_{\substack{s\in S \\ s_i = j}}\psi(s)[u_i(k, s_{-i}) - u_i(s)] \,.
\end{alignat}
Luego, el resultado es inmediato de la definición de $\varepsilon$-equilibrio correlacionado y de la definición de $R_i^t(j, k)$.
\end{proof}

\subsubsection{Procedimiento B: Vector invariante de probabilidad}

Este procedimiento es una variación del anterior. Sin embargo, a tiempo $t+1$ las probabilidades de transición de la estrategia utilizada por el jugador $i$ son determinadas por la matriz estocástica (derecha) $M^i_t$ definida en \eqref{eq:proc-A}; i.e., $M^i_t(j,k)=\frac{1}{\mu}R^i_t(j,k)$ si $k\neq j$, y $M^i_t(j,j)=1-\frac{1}{\mu}\sum_{k\in S_i,k\neq j} R^i_t(j,k)$.

Considere un vector (fila) invariante de probabilidad $q^i_t$, donde $q^i_t\in \Delta(S_i)$, para la matriz $M^t$. Es decir, $q^i_t$ satisface $q^i_t \times M^i_t = q^i_t$ (dicho vector simpre existe):
\begin{alignat}{1}
  q^i_t(j)\ 
    =\ \sum_{k\in S_i} q^i_t(k) M^i_t(k,j)\ 
    =\ \bigg[\sum_{k \in S_i, k \neq j} q^i_t(k)\frac{1}{\mu}R^i_t(k,j)\bigg] + q_i^t(j)\biggl[1 - \frac{1}{\mu}\sum_{k \in S_i, k \neq j} R^i_t(j,k)\biggr]
\end{alignat}
para todo $j \in S_i$. Definamos $R_t^i(j, j) = 0$, luego:
\begin{alignat}{3}
  &
  & q^i_t(j)\ &=\ \biggl[\sum_{k \in S_i} q^i_t(k)\frac{1}{\mu}R^i_t(k,j)\biggr] + q^i_t(j)\biggl[1 - \sum_{k \in S_i} \frac{1}{\mu} R^i_t(j,k)\biggr] \\
  &\Rightarrow\quad
  &\mu q_t^i(j)\ &=\ \biggl[\sum_{k \in S_i}q^i_t(k)R^i_t(k,j)\biggr] + q^i_t(j)\biggl[\mu - \sum_{k \in S_i} R^i_t(j, k)\biggr] \\
  &\Rightarrow\quad
  &\mu q^i_t(j)\ & =\ \biggl[\sum_{k \in S_i}q^i_t(k)R^i_t(k,j)\biggr] + \mu q^i_t(j) - q^i_t(j)\sum_{k\in S_i} R^i_t(j,k) \,.
\end{alignat}
Por lo tanto,
\begin{alignat}{1}
\label{eq:proc-B}
q^i_t(j)\sum_{k \in S_i} R^i_t(j,k)\ =\ \sum_{k \in S_i} q_t^i(k)R_i^t(k,j) \,.
\end{alignat}

\begin{theorem}
Supongamos que a cada período $t+1$, el jugador $i$ elige las estrategias acorde a un vector de distribución de probabilidad $q_t^i$ que satisface \eqref{eq:proc-B}. Entonces, $R^i_t(j, k)$ converge a cero (a. s.) para todo $j, k \in S_i$ con $j \neq k$.
\end{theorem}

\begin{proof}
La prueba es una aplicación directa del Teorema de Aproximación de Blackwell con $L$, $v$ y $\mathcal{C}$ definidos de la siguiente manera:
\begin{itemize}[noitemsep]
  \item $L = \{ (j, k) \in S_i \times S_{i}  : j \neq k \}$
  \item $v(s_i, s_{-i}) \in \mathbb{R}^L$ dado por
    \begin{alignat}{1}
      [v(s_i, s_{-i})](j, k)\ =\  
        \begin{cases}
          u_i(k, s_{-i}) - u_i(j, s_{-i}) & \text{si } s_i = j \\
          0 & \text{en otro caso,}
        \end{cases}
    \end{alignat}
  \item $\mathcal{C} = \mathbb{R}^L_{-} = \{x \in \mathbb{R}^L : x_i \leq 0\ \forall i \in L \}$ es decir, el ortante negativo.
\end{itemize}
Demostraremos que $\mathcal{C}$ es alcanzable por $i$.
Note que:
\begin{alignat}{1}
	w_{\mathcal{C}}(\lambda)\ =\ \sup\{\lambda \cdot c : c \in \mathcal{C} \}\ =\ \sup \{\sum_{i \in L} \lambda_i c_i : c_i \leq 0 \} \,.
\end{alignat}
Luego, si $\lambda_i \geq 0$, $\forall i \in L$, entonces $\lambda \cdot c \leq 0$ para todo $c \in \mathcal{C}$, y $w_{\mathcal{C}}(\lambda) = 0$. Por otra parte, si $\lambda_i < 0$ para algún $i\in N$, entonces $c_i \lambda_i$ no está acotado superiormente y  $w_{\mathcal{C}}(\lambda) = \infty$. Luego,
\begin{alignat}{1}
  w_{\mathcal{C}}\ =\  
	\begin{cases}
	  0 & \text{si } \lambda \in \mathbb{R}^L_+ \,, \\
	  \infty & \text{en caso contrario.}
	\end{cases}
\end{alignat}
Por otra parte, se tiene que:
\begin{alignat}{1}
	\lambda \cdot v(q_{\lambda}, s_{-i})\ 
	  &=\ \sum_{(j,k) \in L} \lambda(j,k) \cdot [v(q_{\lambda}, s_{-i})](j, k) \\
	&=\ \sum_{(j,k) \in L} \lambda(j, k)\left[\sum_{s_i \in S_i} q_{\lambda}(s_i) v(s_i, s_{-i}) \right](j, k) \\
	&=\ \sum_{(j,k) \in L} \lambda(j, k) q_{\lambda}(j) [v(j, s_{-i})](j, k) \\
	&=\ \sum_{(j,k) \in L} \lambda(j, k) q_{\lambda}(j) [u_i(k, s_{-i}) - u_i(j, s_{-i})] \\
	&=\ \sum_{(j,k) \in L} \lambda(j, k) q_{\lambda}(j)u_i(k, s_{-i}) - \sum_{(j,k) \in L} \lambda(j, k) q_{\lambda}(j)u_i(j, s_{-i}) \\
	&=\ \sum_{k \in S_i} u_i(k, s_{-i}) \sum_{j \in S_i} \lambda(j, k) q_{\lambda}(j) - \sum_{j \in S_i} q_{\lambda}(j)u_i(j, s_{-i}) \sum_{k \in S_i} \lambda(j, k) \\
	&=\ \sum_{j \in S_i} u_i(j, s_{-i}) \sum_{k \in S_i} \lambda(k, j) q_{\lambda}(k) - \sum_{j \in S_i} q_{\lambda}(j)u_i(j, s_{-i}) \sum_{k \in S_i} \lambda(j, k) \\
	&=\ \sum_{j \in S_i} u_i(j, s_{-i}) \left[ \sum_{k \in S_i} \lambda(k, j) q_{\lambda}(k) - q_{\lambda}(j) \sum_{k \in S_i} \lambda(j, k) \right] \,.
\end{alignat}
Defina
\begin{alignat}{1}
  \alpha(j)\ =\ \sum_{k \in S_i} \lambda(k, j) q_{\lambda}(k) - q_{\lambda}(j) \sum_{k \in S_i} \lambda(j, k) \,.
\end{alignat}
Entonces, $\lambda \cdot v(q_{\lambda}, s_{-i}) = \sum_{j \in S_i} u_i(j, s_{-i}) \alpha(j)$.
Luego, en este caso, la condición del Teorema \ref{theo:blackwell} es equivalente a:
\begin{alignat}{1}
	\sum_{j \in S_i} u_i(j, s_{-i}) \alpha(j)\ \leq\ 0 \,.
\end{alignat}
Si se elige $q_{\lambda}$ que cumpla:
\begin{alignat}{1}
  q_{\lambda}(j) \sum_{k \in S_i} \lambda(j, k)\ =\ \sum_{k \in S_i} \lambda(k, j) q_{\lambda}(k)
\end{alignat}
para todo $j \in S_i$, entonces $\alpha(j)=0$ para $j\in S_i$, y la condición del Teorema~\ref{theo:blackwell} se cumple como igualdad cuando $\mathcal{C} = \mathbb{R}^{L}_-$.

Por otra parte, sea $D_t=\frac{1}{t}\sum_{\tau=1}^t v(s_\tau)$ el promedio de los vectores de pago a tiempo $t$. Entonces,
\begin{alignat}{1}
  D_t[j, k]\ &=\ \sum_{\tau=1}^{t} v(s_{\tau})[j,k]\
	=\ \sum_{1\leq\tau \leq t, s_i^{\tau} = j} u_i(k, s_{-i}^{\tau}) - u_i(j, s_{-i}^{\tau})\
	=\ D_i^t(j, k) \,.
\end{alignat}
Para $x \notin \mathbb{R}^-$, $F(x) = x^-$ y $\lambda (x) = x - x^- = x^+$, obteniendo 
\begin{alignat}{1}
	\lambda(D_t)\ =\ (R_t^i(j, k))_{(j, k) \in L} \,.
\end{alignat}
Luego, usar una estrategia que cumpla
\begin{alignat}{1}
	q_{\lambda}(j) \sum_{k \in S_i} \lambda(j, k)\ =\  \sum_{k \in S_i} q_{\lambda}(k) \lambda(k, j)
\end{alignat}
cuando $\lambda(j, k) = [D_i^t(j, k)]^+ = R_t^i(j, k)$ es equivalente que la estrategia $p_{t+1}^i \in \Delta(S_i)$ cumpla con
\begin{alignat}{1}
	p_{t+1}^i (j) \sum_{k \in S_i} R_i^t(j, k)\ =\ \sum_{k \in S_i} R_i^t(k, j) p_{t+1}^i(k)
\end{alignat}
Aplicando el Teorema \ref{theo:blackwell} se tiene que al usar dicha estrategia, $D_t$ alcanza a $\mathbb{R}^-$ que es equivalente a que $R_i^t(j, k) \rightarrow 0$ para todo $j, k \in S_i$.
\end{proof}

\subsubsection{Procedimiento C: Regret incondicional}

El tercer procedimiento no conduce necesariamente a un equilibrio correlacionado. Sin embargo es considerado ``universalmente consistente'' (Definición \ref{def:proc-univ-consistente}). En este procedimiento, el pago promedio del jugador $i$, en el límite, no es peor a el pago si él hubiese jugado cualquier estrategia constante $k$, para todo $\tau \leq t$.

\begin{definition}
\label{def:proc-univ-consistente}
Un procedimiento adaptativo es \textbf{universalmente consistente} para el jugador $i$ si:
\begin{alignat}{1}
	\limsup_{t \rightarrow \infty } \left[ \max_{k \in S_i} \frac{1}{t} \sum_{\tau = 1}^{t} u_i(k, s_{-i}^{\tau}) - \frac{1}{t} \sum_{\tau = 1}^{t} u_i(s_{\tau}) \right]\ \leq\ 0\quad (a. s.)
\end{alignat}
\end{definition}
El procedimiento es definido a continuación. A tiempo $t$, definimos
\begin{alignat}{1}
D_i^t(k)\ &=\ \frac{1}{t} \sum_{\tau = 1}^{t} u_i(k, s_{-i}^{\tau}) - u_i(s_{\tau}) \,, \\
R_i^t(k)\ &=\ [D_i^t(k)]^+\ =\ \max(0, D_i^t(k)) \,.
\end{alignat}
Luego, la distribución de probabilidad a tiempo $t+1$, $p_{t+1}^i \in \Delta(S_i)$, es definida como sigue:
\begin{alignat}{1}
\label{eq:proc-C}
  p_{t+1}^i(k)\ =\ \frac{R_i^t(k)}{\sum_{k'\in S_i} R_i^t(k')}
\end{alignat}
si el denominador es positivo, y de forma arbitraria en caso contrario. Note que las probabilidades son elegidas de forma proporcional a $R_i^t(k)$ que será denominado \textit{regret} incondicional (en contraste al \textit{regret} condicional definido previamente).

\begin{theorem}
\label{theo:conv-proc-C}
El procedimiento adaptativo definido en \eqref{eq:proc-C} es universalmente consistente para el jugador $i$.
\end{theorem}

\begin{proof}
La prueba es similar a la del procedimiento anterior. Se definen $L$, $v$ y $\mathcal{C}$ del Teorema \ref{theo:blackwell} de la siguiente manera:
\begin{itemize}[noitemsep]
  \item $L = S_i$,
  \item $v = v(s_i, s_{-i}) \in \mathbb{R}^L$ dada por:
    $[v(s_i, s_{-i})](k)=u_i(k, s_{-i}) - u_i(s_i, s_{-i})$,
  \item $\mathcal{C} = \mathbb{R}^L_- = \{x \in \mathbb{R}^L : x_i \leq 0\ \forall i \in L \}$ (i.e.\ el ortante negativo).
\end{itemize}
Se demostrará que $\mathcal{C}$ es alcanzable por $i$. Al igual que antes, se tiene que:
\begin{alignat}{1}
  w_{\mathcal{C}}\ =\ 
    \begin{cases}
	  0 & \text{si } \lambda \in \mathbb{R}^L_+ \,, \\
      \infty & \text{en caso contrario.}
    \end{cases}
\end{alignat}
Por otra parte,
\begin{alignat}{1}
	\lambda \cdot v(q_{\lambda}, s_{-i})\ 
	&=\ \sum_{k \in L} \lambda(k) \cdot [v(q_{\lambda}, s_{-i})](k) \\
	&=\ \sum_{k \in S_i} \lambda(k) \cdot \sum_{j \in S_i} q_{\lambda}(j)[v(j, s_{-i})] (k) \\
	&=\ \sum_{k \in S_i} \lambda(k) \cdot \sum_{j \in S_i} q_{\lambda}(j) [u_i(k, s_{-i}) - u_i(j, s_{-i})] \\
	&=\ \sum_{\substack{k \in S_i \\ j \in S_i}} \lambda(k) q_{\lambda}(j) [u_i(k, s_{-i}) - u_i(j, s_{-i})] \\
	&=\ \sum_{\substack{k \in S_i \\ j \in S_i}} \lambda(k) q_{\lambda}(j) u_i(k, s_{-i}) - \sum_{\substack{k \in S_i \\ j \in S_i}} \lambda(k) q_{\lambda}(j) u_i(j, s_{-i}) \\
	&=\ \sum_{\substack{j \in S_i \\ k \in S_i}} u_i(j, s_{-i}) \lambda(j) q_{\lambda}(k)  - \sum_{\substack{j \in S_i \\ j \in S_i}} u_i(j, s_{-i}) \lambda(k) q_{\lambda}(j) \\
	&=\ \sum_{\substack{j \in S_i \\ k \in S_i}} u_i(j, s_{-i}) [\lambda(j) q_{\lambda}(k)  - \lambda(k) q_{\lambda}(j)] \\
	&=\ \sum_{j \in S_i} u_i(j, s_{-i}) \left[ \lambda(j) \sum_{k \in S_i} q_{\lambda}(k)  - q_{\lambda}(j) \sum_{k \in S_i} \lambda(k)  \right] \\
	&=\ \sum_{j \in S_i} u_i(j, s_{-i}) \left[ \lambda(j) - q_{\lambda}(j) \sum_{k \in S_i} \lambda(k) \right] \,.
\end{alignat}
La última igualdad porque $\sum_{k\in S_i} q_{\lambda}(k)=1$. Luego, si se define:
\begin{alignat}{1}
	\alpha(j)\ =\ \lambda(j) - q_{\lambda}(j) \sum_{k \in S_i} \lambda(k) \,,
\end{alignat}
obtenemos $\lambda \cdot v(q_{\lambda}, s_{-i}) = \sum_{j \in S_i} u_i(j, s_{-i})\alpha(j)$.
Note que si $q_{\lambda(j)} = \frac{\lambda(j)}{\sum_{k \in S_i} \lambda(k)}$, entonces $\alpha(j) = 0$ para todo $j \in S_i$ y se cumple la condición del Teorema \ref{theo:blackwell} en forma de igualdad. Además, para $D_t=\frac{1}{t} \sum_{\tau = 1}^{t} v(s_{\tau})$, tenemos
\begin{alignat}{1}
	D_t[k]\ =\ \sum_{\tau = 1}^{t} v(s_{\tau})[k]\ =\ \sum_{\tau \leq t }[u_i(k, s_{-i}^{\tau}) - u_i(s_{\tau})]\ =\  D_i^t(k) \,.
\end{alignat}
Luego $F(D_t) = D_t^-$ y $\lambda(D_t) = D_t^+ = (R_i^t(k))_{k \in S_i}$, obteniendo:
\begin{alignat}{1}
	q_{\lambda(D_t)}\ =\ \frac{[\lambda(D_t)](j)}{\sum_{k \in S_i}[\lambda(D_t)](k)}\ =\ \frac{R_i^t(j)}{\sum_{k \in S_i} R_i^t(k)}
\end{alignat}
Al elegir $p_{t+1}(j) = q_{\lambda(D_t)}(j) = \frac{R_i^t (j)}{\sum_{k \in S_i} R_i^t(k)}$, se obtiene que $D_t$ alcanza a $\mathbb{R^-}$, lo cual es equivalente a que $R_i^t(j) \rightarrow 0$ para todo $j \in S_i$.
\end{proof}
